# modules/asset_retriever.py
import json
import numpy as np
from typing import Dict, List
from sentence_transformers import SentenceTransformer
from utils.llm_utils import call_llm
from utils.config import ASSET_MODEL

# --- ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã¨DBã‚’ä¸€åº¦ã ã‘ãƒ­ãƒ¼ãƒ‰ ---
print("[Asset Retriever] CLIPãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
CLIP_MODEL = SentenceTransformer('clip-ViT-B-32')
with open("library/asset_database.json", 'r', encoding='utf-8') as f:
    ASSET_DATABASE = json.load(f)
# é«˜é€Ÿãªæ¤œç´¢ã®ãŸã‚ã«ã€ãƒ™ã‚¯ãƒˆãƒ«ã‚’Numpyé…åˆ—ã«å¤‰æ›ã—ã¦ãŠã
for asset in ASSET_DATABASE:
    asset['image_embedding'] = np.array(asset['image_embedding'])
    asset['text_embedding'] = np.array(asset['text_embedding'])
print("[Asset Retriever] âœ”ï¸ ãƒ­ãƒ¼ãƒ‰å®Œäº†ã€‚")
# ----------------------------------------------------
def predict_asset_scales(assets_with_paths: Dict[str, str]) -> Dict[str, float]:
    """
    ã€æ–°è¦è¿½åŠ ã€‘LLMã‚’ä½¿ã„ã€ã‚¢ã‚»ãƒƒãƒˆã®ç¾å®Ÿçš„ãªé«˜ã•ã‚’ãƒ¡ãƒ¼ãƒˆãƒ«å˜ä½ã§äºˆæ¸¬ã™ã‚‹ã€‚
    """
    print("  - LLMã«ã‚¢ã‚»ãƒƒãƒˆã®ç¾å®Ÿçš„ãªé«˜ã•ã®äºˆæ¸¬ã‚’ä¾é ¼ä¸­...")
    
    asset_names = list(assets_with_paths.keys())
    
    prompt = f"""
    ä»¥ä¸‹ã®3Dã‚¢ã‚»ãƒƒãƒˆãƒªã‚¹ãƒˆãŒã‚·ãƒ¼ãƒ³ã«é…ç½®ã•ã‚Œã¾ã™ã€‚
    å„ã‚¢ã‚»ãƒƒãƒˆã®ç¾å®Ÿçš„ãªé«˜ã•ã‚’ãƒ¡ãƒ¼ãƒˆãƒ«å˜ä½ã§äºˆæ¸¬ã—ã€Pythonã®è¾æ›¸å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
    ä¾‹ãˆã°ã€äººé–“ãªã‚‰1.7ã€è»Šãªã‚‰1.5ã®ã‚ˆã†ã«å¸¸è­˜çš„ãªå€¤ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚

    ã‚¢ã‚»ãƒƒãƒˆãƒªã‚¹ãƒˆ: {asset_names}

    å‡ºåŠ›å½¢å¼ã®ä¾‹:
    ```json
    {{
      "Slum house": 10.0,
      "Hunter": 1.65,
      "Street Lamp": 3.0
    }}
    ```
    """
    
    predicted_scales = call_llm(ASSET_MODEL, prompt)
    
    if not isinstance(predicted_scales, dict):
        print("    [Warning] é«˜ã•ã®äºˆæ¸¬ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
        return {name: 1.0 for name in asset_names} # å¤±æ•—ã—ãŸå ´åˆã¯ã™ã¹ã¦1.0ã¨ã™ã‚‹
        
    print("    âœ”ï¸ é«˜ã•ã®äºˆæ¸¬ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
    return predicted_scales

def retrieve_assets(user_query: str) -> Dict[str, Dict]:
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¯ã‚¨ãƒªã‹ã‚‰ã‚¢ã‚»ãƒƒãƒˆã‚’æ¤œç´¢ã—ã€ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã¨äºˆæ¸¬ã•ã‚ŒãŸé«˜ã•ã‚’è¿”ã™ã€‚
    """
    print("\n--- [Step 1] ğŸ–¼ï¸ ã‚¢ã‚»ãƒƒãƒˆé¸å®š (é«˜ç²¾åº¦) ---")
    
    # ... (LLMã«ã‚ˆã‚‹ã‚¢ã‚»ãƒƒãƒˆèª¬æ˜ã®ç”Ÿæˆéƒ¨åˆ†ã¯å¤‰æ›´ãªã—) ...
    assets_to_find = call_llm(ASSET_MODEL, f"...") # promptã¯çœç•¥

    # ... (2æ®µéšæ¤œç´¢ã«ã‚ˆã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®å–å¾—éƒ¨åˆ†ã¯å¤‰æ›´ãªã—) ...
    retrieved_assets_paths = {}
    # ...
            
    # ã€è¿½åŠ ã€‘å–å¾—ã—ãŸã‚¢ã‚»ãƒƒãƒˆã®ã‚¹ã‚±ãƒ¼ãƒ«ã‚’äºˆæ¸¬
    predicted_scales = predict_asset_scales(retrieved_assets_paths)
    
    # ã€å¤‰æ›´ã€‘è¿”ã‚Šå€¤ã«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã¨ã‚¹ã‚±ãƒ¼ãƒ«(é«˜ã•)ã®ä¸¡æ–¹ã‚’å«ã‚ã‚‹
    final_assets_info = {}
    for name, path in retrieved_assets_paths.items():
        final_assets_info[name] = {
            "file_path": path,
            "height": predicted_scales.get(name, 1.0) # äºˆæ¸¬ãŒãªã‘ã‚Œã°ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ1.0
        }
        
    return final_assets_info

def find_best_asset_with_reranking(query_description: str, top_k: int = 10) -> Dict:
    """
    ã€æ”¹å–„ç‚¹ã€‘ãƒ†ã‚­ã‚¹ãƒˆã¨ç”»åƒã®ä¸¡æ–¹ã‚’ç”¨ã„ã¦ã€æœ€ã‚‚ä¸€è‡´ã™ã‚‹ã‚¢ã‚»ãƒƒãƒˆã‚’æ¤œç´¢ã™ã‚‹ã€‚
    è«–æ–‡ã§è¨€åŠã•ã‚Œã¦ã„ã‚‹2æ®µéšã®æ¤œç´¢ãƒ—ãƒ­ã‚»ã‚¹ã‚’å®Ÿè£…ã€‚
    """
    # 1. æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
    query_embedding = CLIP_MODEL.encode(query_description)
    
    # --- Stage 1: ãƒ†ã‚­ã‚¹ãƒˆé¡ä¼¼åº¦ã«ã‚ˆã‚‹å€™è£œã®çµã‚Šè¾¼ã¿ ---
    text_scores = []
    for asset in ASSET_DATABASE:
        score = np.dot(query_embedding, asset['text_embedding'])
        text_scores.append((score, asset))
    
    # ã‚¹ã‚³ã‚¢ã§é™é †ã«ã‚½ãƒ¼ãƒˆã—ã€ä¸Šä½kä»¶ã‚’å–å¾—
    text_scores.sort(key=lambda x: x[0], reverse=True)
    top_k_candidates = [asset for score, asset in text_scores[:top_k]]

    if not top_k_candidates:
        return None

    # --- Stage 2: ç”»åƒé¡ä¼¼åº¦ã«ã‚ˆã‚‹å†ãƒ©ãƒ³ã‚¯ä»˜ã‘ (Re-ranking) ---
    best_asset = None
    highest_image_score = -1

    print(f"    - ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢ã§{len(top_k_candidates)}ä»¶ã®å€™è£œã‚’ç™ºè¦‹ã€‚ç”»åƒã§å†ãƒ©ãƒ³ã‚¯ä»˜ã‘ã‚’å®Ÿè¡Œ...")
    for candidate_asset in top_k_candidates:
        # å€™è£œã‚¢ã‚»ãƒƒãƒˆã®ç”»åƒåŸ‹ã‚è¾¼ã¿ã¨ã‚¯ã‚¨ãƒªã®ãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿ã§é¡ä¼¼åº¦ã‚’è¨ˆç®—
        image_score = np.dot(query_embedding, candidate_asset['image_embedding'])
        
        if image_score > highest_image_score:
            highest_image_score = image_score
            best_asset = candidate_asset
            
    return best_asset

def retrieve_assets(user_query: str) -> Dict[str, str]:
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¯ã‚¨ãƒªã‹ã‚‰ã‚¢ã‚»ãƒƒãƒˆã®èª¬æ˜ã‚’LLMã§ç”Ÿæˆã—ã€
    æœ€ã‚‚ä¸€è‡´ã™ã‚‹ã‚¢ã‚»ãƒƒãƒˆã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’è¿”ã™ã€‚
    """
    print("\n--- [Step 1] ğŸ–¼ï¸ ã‚¢ã‚»ãƒƒãƒˆé¸å®š (é«˜ç²¾åº¦) ---")
    
    prompt = f"""
    ä»¥ä¸‹ã®ã‚¯ã‚¨ãƒªã«å¿…è¦ãªã‚¢ã‚»ãƒƒãƒˆã®ãƒªã‚¹ãƒˆã¨ã€ãã‚Œãã‚Œã®è©³ç´°ãªè¦–è¦šçš„èª¬æ˜ã‚’JSONè¾æ›¸ã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
    ã‚¯ã‚¨ãƒª: "{user_query}"
    ```json
    {{ "asset_name_1": "description_1", "asset_name_2": "description_2" }}
    ```
    """
    assets_to_find = call_llm(ASSET_MODEL, prompt)
    
    if not isinstance(assets_to_find, dict):
        print("  [Warning] LLMã‹ã‚‰æœ‰åŠ¹ãªã‚¢ã‚»ãƒƒãƒˆãƒªã‚¹ãƒˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        return {}

    retrieved_assets = {}
    print("âœ”ï¸ é¸å®šã•ã‚ŒãŸã‚¢ã‚»ãƒƒãƒˆ:")
    for asset_name, description in assets_to_find.items():
        print(f"  - '{description}' ã‚’æ¤œç´¢ä¸­...")
        
        # ã€æ”¹å–„ç‚¹ã€‘æ–°ã—ã„2æ®µéšæ¤œç´¢é–¢æ•°ã‚’å‘¼ã³å‡ºã™
        best_match = find_best_asset_with_reranking(description)
        
        if best_match:
            print(f"    âœ… ç™ºè¦‹ (ç”»åƒã‚¹ã‚³ã‚¢ã§é¸å®š): {best_match['file_path']}")
            retrieved_assets[asset_name] = best_match['file_path']
        else:
            print(f"    âŒ è©²å½“ã‚¢ã‚»ãƒƒãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            retrieved_assets[asset_name] = None
            
    return retrieved_assets